{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 04"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Let $\\theta_1$ and $\\theta_2$ be real valued parameters in $[0,1]$ and consider the generative model\n",
    "\\begin{align*}\n",
    "\\theta_1 &\\sim \\theta_1\\text{-prior}\\\\\n",
    "\\theta_2 &\\sim \\theta_2\\text{-prior}\\\\\n",
    "\\hat{y} &= \\frac{\\theta_1+x^2}{\\theta_2\\cdot x}\\\\\n",
    "y &\\sim \\mathcal{N} (\\hat{y}, 1)\n",
    "\\end{align*}\n",
    "\n",
    "a. Use pyro to implement the model as a function `model(theta1_prior, theta2_prior, x, obs)`, where `theta1_prior` and `theta2_prior` are pyro.distributions objects, `x` and `obs` are torch tensors, and draws from the normal distribution are conditioned on `obs`.\n",
    "\n",
    "b. Choose two suitable prior distributions for $\\theta_1$ and $\\theta_2$ (e.g. suitably rescaled Normal or Beta distributions)  and use HMC or NUTS algorithm to find their posterior distributions given the observations\n",
    "\n",
    "\\begin{align*}\n",
    "x&=(47,87,20,16,38,5)\\\\\n",
    "y&=(58.76, 108.75,  25.03,  20.03,  47.51,  6.37).\n",
    "\\end{align*}\n",
    "\n",
    "\n",
    "c. Discuss how different prior distributions lead to different estimates of $\\theta_1$ and $\\theta_2$. Comment on the convergence checks and plot the posterior distributions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "A bivariate Gibbs sampler for a vector $x=(x_1,x_2)$ draws iteratively from the posterior conditional distributions in the following way:\n",
    "- choose a starting value $p(x_1|x_2^{(0)})$\n",
    "- for each iteration $i$:\n",
    "    - draw $x_2(i)$ from $p(x_2|x_1^{(i-1)})$\n",
    "    - draw $x_1(i)$ from $p(x_1|x_2^{(i)})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a. Supposing that samples are drawn from a bivariate normal distribution\n",
    "\n",
    "$$\n",
    "{x_1 \\choose x_2} \\sim \\mathcal{N} \\Bigg[ {0 \\choose 0} , \\begin{pmatrix} 1 & \\rho \\\\ \\rho & 1 \\end{pmatrix} \\Bigg],\n",
    "$$\n",
    "    implement a Gibbs sampler function which takes as inputs the parameter `rho`, the number of iterations `iters` and the number of warmup draws `warmup`.\n",
    "\n",
    "b. Use your implementation of Gibbs sampler to infer the parameters $\\theta=(\\theta_1,\\theta_2)$ from **Exercise 1**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
